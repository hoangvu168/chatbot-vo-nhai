import os
import openai
import chromadb
from dotenv import load_dotenv
from chromadb.config import Settings
from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction

# ====== 1. Táº¢I API KEY Tá»ª FILE .env ======
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# ====== 2. KHá»I Táº O EMBEDDING FUNCTION VÃ€ CLIENT ======
embedding_function = OpenAIEmbeddingFunction(
    api_key=openai.api_key,
    model_name="text-embedding-ada-002"
)

client = chromadb.Client(Settings(
    chroma_db_impl="duckdb+parquet",
    persist_directory="./vector_store"
))

collection = client.get_or_create_collection(
    "thu_tuc_hanh_chinh",
    embedding_function=embedding_function
)

# ====== 3. NHáº¬P CÃ‚U Há»I NGÆ¯á»œI DÃ™NG ======
question = input("ğŸ‘¤ NgÆ°á»i dÃ¹ng há»i: ")

# ====== 4. TÃŒM KIáº¾M CÃC ÄOáº N VÄ‚N LIÃŠN QUAN ======
results = collection.query(
    query_texts=[question],
    n_results=3
)

# ====== 5. Táº O NGá»® Cáº¢NH Tá»ª Káº¾T QUáº¢ ======
context = "\n\n".join(results["documents"][0])

# ====== 6. Táº O PROMPT CHO GPT ======
prompt = f"""Báº¡n lÃ  trá»£ lÃ½ hÃ nh chÃ­nh cÃ´ng cá»§a huyá»‡n VÃµ Nhai. Tráº£ lá»i cÃ¢u há»i dÆ°á»›i Ä‘Ã¢y dá»±a trÃªn thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p tá»« cÃ¡c tÃ i liá»‡u hÃ nh chÃ­nh:

ThÃ´ng tin tham kháº£o:
{context}

CÃ¢u há»i: {question}

Tráº£ lá»i chi tiáº¿t vÃ  Ä‘áº§y Ä‘á»§ nháº¥t:"""

# ====== 7. Gá»¬I YÃŠU Cáº¦U Äáº¾N GPT ======
response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[{"role": "user", "content": prompt}],
    temperature=0.3
)

# ====== 8. HIá»‚N THá»Š Káº¾T QUáº¢ ======
print("\nğŸ¤– Trá»£ lÃ½ tráº£ lá»i:\n")
print(response.choices[0].message.content)
