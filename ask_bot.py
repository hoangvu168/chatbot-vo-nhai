import openai
import chromadb
from chromadb.config import Settings
from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction

openai.api_key = "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"  # Thay b·∫±ng API KEY

# 1. Kh·ªüi t·∫°o Chroma
embedding_function = OpenAIEmbeddingFunction(
    api_key=openai.api_key,
    model_name="text-embedding-ada-002"
)
client = chromadb.Client(Settings(chroma_db_impl="duckdb+parquet", persist_directory="./vector_store"))
collection = client.get_or_create_collection("thu_tuc_hanh_chinh", embedding_function=embedding_function)

# 2. Nh·∫≠p c√¢u h·ªèi ng∆∞·ªùi d√πng
question = input("Ng∆∞·ªùi d√πng h·ªèi: ")

# 3. T√¨m c√°c ƒëo·∫°n vƒÉn li√™n quan nh·∫•t
results = collection.query(
    query_texts=[question],
    n_results=3
)

# 4. K·∫øt h·ª£p c√°c ƒëo·∫°n li√™n quan ƒë·ªÉ g·ª≠i GPT
context = "\n\n".join(results["documents"][0])

prompt = f"""B·∫°n l√† tr·ª£ l√Ω h√†nh ch√≠nh c√¥ng c·ªßa huy·ªán V√µ Nhai. Tr·∫£ l·ªùi c√¢u h·ªèi d∆∞·ªõi ƒë√¢y d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p t·ª´ c√°c t√†i li·ªáu h√†nh ch√≠nh:

Th√¥ng tin tham kh·∫£o:
{context}

C√¢u h·ªèi: {question}

Tr·∫£ l·ªùi chi ti·∫øt v√† ƒë·∫ßy ƒë·ªß nh·∫•t:"""

response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[{"role": "user", "content": prompt}],
    temperature=0.3
)

print("\nü§ñ Tr·ª£ l√Ω tr·∫£ l·ªùi:\n")
print(response.choices[0].message.content)
